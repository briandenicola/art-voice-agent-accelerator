# ---------------------------------------------------------------------
# ARTAgent â€“ Base Agent Template
# ---------------------------------------------------------------------
# Copy this template to create new ARTAgent configurations.
# Update the `agent`, `model`, `voice`, `prompts`, and `tools` sections
# and keep the metadata block aligned with your runtime requirements.

agent:
  name: YourAgentName
  creator: YourName
  organization: YourOrganization
  description: |
    Brief description of the agent's purpose and routing rules.

model:
  deployment_id: gpt-4o                     # Replace with your Azure OpenAI deployment
  max_completion_tokens: 2040               # Response length cap for streaming completions
  max_tokens: 4096                          # Legacy compatibility with chat-completions flow
  temperature: 0.7                          # REMOVE for Responses API models (gpt-5, gpt-4.1, o3-mini, etc.)
  top_p: 0.9                                # REMOVE for Responses API models (gpt-5, gpt-4.1, o3-mini, etc.)
  # service_tier: standard                  # Optional Azure OpenAI service tier override
  # Optional Responses API overrides; remove if temperature/top_p remain configured above.
  reasoning:
    effort: medium                          # Applies to reasoning-capable deployments only
  text:
    verbosity: low                          # Omit when temperature/top_p are defined
voice:
  name: en-US-Emma:DragonHDLatestNeural     # Azure Speech voice for TTS output
  style: chat                               # Voice style (chat, professional, friendly, etc.)
  rate: "+5%"                               # Speaking rate adjustment for synthesized audio
  # temperature: 0.8                        # Optional voice temperature for Dragon voices

prompts:
  path: voice_agent_base.jinja              # Prompt template path relative to prompt_store
  parameters:
    app_name: MyVoiceAssistant              # Example template parameter (delete if unused)

tools:
  - authenticate_caller
  - escalate_human
  - escalate_emergency
  - example_custom_tool:
      function:
        name: example_custom_tool
        description: Demo tool payload for reference
        parameters:
          type: object
          properties:
            example_field:
              type: string
              description: Example parameter passed from the model
          required:
            - example_field

metadata:
  runtime:
    responses_api:
      enabled: false                        # Set true to opt into responses.create runtime
      applies_to_models: ["gpt-5", "gpt-4.1", "o3-mini"]  # Deployments that require Responses API shape
      modalities: ["text", "audio"]         # Supported response modalities (text/audio/image)
      audio:
        voice: en-US-Emma:DragonHDLatestNeural
        format: wav
      input_audio_transcription:
        model: whisper-1
      reasoning:
        effort: medium                      # Adjust for reasoning-capable deployments (low|medium|high)
      text:
        verbosity: low
      response_format: text                 # Use json_schema / text / other Response API formats as needed
      disable_sampling_params: true         # Helps runtime drop temperature/top_p automatically
      extra_options:
        parallel_tool_calls: true
        max_output_tokens: 2048             # Responses API replacement for max_completion_tokens
  tags:
    - base-template
  notes: >
    When targeting Responses API deployments (gpt-5, gpt-4.1, o3-mini, etc.)
    set metadata.runtime.responses_api.enabled to true and remove the temperature/top_p
    keys from the model section. Chat Completions-compatible models (gpt-4o, gpt-4o-mini, etc.)
    can keep those sampling controls in place.
